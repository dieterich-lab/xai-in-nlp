{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c90828-67aa-4aab-91da-58b7421c9dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/beegfs/homes/rsari/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f755372-cad7-43e8-8aeb-e1effa37a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag = {0: 'Anrede', 1: 'Diagnosen', 2: 'AllergienUnverträglichkeitenRisiken', 3: 'Anamnese', 4: 'Medikation', 5: 'KUBefunde', 6: 'Befunde', 7: 'EchoBefunde', 8: 'Zusammenfassung', 9: 'Mix', 10: 'Abschluss'}\n",
    "tag2id = {tag: id for id, tag in id2tag.items()}\n",
    "\n",
    "labels = list(id2tag.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa217824-3866-44a9-b167-8baac5eb71e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "lines = []\n",
    "with open(\"../BertSeqCA.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    lines = lines[35884:]\n",
    "    for l in lines:\n",
    "        if any([i for i in labels if i in l]):\n",
    "            lab, pre, rec, f1, count = l.split()\n",
    "            scores[lab] = {\"pre\": pre, \"rec\": rec, \"f1\": f1, \"count\": count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98189d10-7a5a-4a77-8d08-c117fc94ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                  Precision    Recall    F1-score    Test instance count\n",
      "-----------------------------------  -----------  --------  ----------  ---------------------\n",
      "Anrede                                      1         1           1                        99\n",
      "Medikation                                  0.99      0.98        0.98                   1627\n",
      "KUBefunde                                   0.99      0.97        0.98                   1105\n",
      "Diagnosen                                   0.96      0.97        0.96                   1738\n",
      "AllergienUnverträglichkeitenRisiken         0.97      0.94        0.96                    236\n",
      "Abschluss                                   0.94      0.99        0.96                   2472\n",
      "Befunde                                     0.93      0.86        0.9                    2519\n",
      "Zusammenfassung                             0.9       0.9         0.9                    2138\n",
      "Anamnese                                    0.9       0.81        0.85                   1097\n",
      "Mix                                         0.76      0.83        0.79                    242\n",
      "EchoBefunde                                 0.6       0.94        0.73                    290\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "l = iter(labels)\n",
    "table = [[n:=next(l), scores[n][\"pre\"], scores[n][\"rec\"], scores[n][\"f1\"], scores[n][\"count\"]] for lab in labels]\n",
    "table = sorted(table, key=lambda x:float(x[3]), reverse = True)\n",
    "table.insert(0, [\"Label\", \"Precision\", \"Recall\", \"F1-score\", \"Test instance count\"])\n",
    "         \n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706a8882-13f9-432b-aadd-f794d70f2fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: (High FP: Other labels retrieved)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Anrede', '1.00'),\n",
       " ('Medikation', '0.99'),\n",
       " ('KUBefunde', '0.99'),\n",
       " ('AllergienUnverträglichkeitenRisiken', '0.97'),\n",
       " ('Diagnosen', '0.96'),\n",
       " ('Abschluss', '0.94'),\n",
       " ('Befunde', '0.93'),\n",
       " ('Zusammenfassung', '0.90'),\n",
       " ('Anamnese', '0.90'),\n",
       " ('Mix', '0.76'),\n",
       " ('EchoBefunde', '0.60')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take second element for sort\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "\n",
    "keys = iter(list(scores.keys()))\n",
    "sorted_pre = sorted([(next(keys), i[y]) for i in scores.values() for y in i if y == \"pre\"], key=takeSecond, reverse=True)\n",
    "\n",
    "print(\"Precision: (High FP: Other labels retrieved)\")\n",
    "sorted_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53aa832-e46d-4dd6-8937-6f9c1bcc6726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: (High FN: Same label not retrieved)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Anrede', '1.00'),\n",
       " ('Abschluss', '0.99'),\n",
       " ('Medikation', '0.98'),\n",
       " ('Diagnosen', '0.97'),\n",
       " ('KUBefunde', '0.97'),\n",
       " ('AllergienUnverträglichkeitenRisiken', '0.94'),\n",
       " ('EchoBefunde', '0.94'),\n",
       " ('Zusammenfassung', '0.90'),\n",
       " ('Befunde', '0.86'),\n",
       " ('Mix', '0.83'),\n",
       " ('Anamnese', '0.81')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = iter(list(scores.keys()))\n",
    "sorted_rec = sorted([(next(keys), i[y]) for i in scores.values() for y in i if y == \"rec\"], key=takeSecond, reverse=True)\n",
    "\n",
    "print(\"Recall: (High FN: Same label not retrieved)\")\n",
    "sorted_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746f14ff-8d71-4848-90d7-68d089e53457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Measure:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Anrede', '1.00'),\n",
       " ('Medikation', '0.98'),\n",
       " ('KUBefunde', '0.98'),\n",
       " ('Abschluss', '0.96'),\n",
       " ('Diagnosen', '0.96'),\n",
       " ('AllergienUnverträglichkeitenRisiken', '0.96'),\n",
       " ('Zusammenfassung', '0.90'),\n",
       " ('Befunde', '0.90'),\n",
       " ('Anamnese', '0.85'),\n",
       " ('Mix', '0.79'),\n",
       " ('EchoBefunde', '0.73')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = iter(list(scores.keys()))\n",
    "sorted_f1 = sorted([(next(keys), i[y]) for i in scores.values() for y in i if y == \"f1\"], key=takeSecond, reverse=True)\n",
    "\n",
    "print(\"F1-Measure:\")\n",
    "sorted_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba2025-4f02-4c02-8529-dc7b001da147",
   "metadata": {},
   "source": [
    "### Get Down to Low vs. High Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02441558-696b-4728-bb71-adc195d2b877",
   "metadata": {},
   "source": [
    "Approach:\n",
    "1. Get training data statistic for lowest label scoring (EchoBefunde), e.g. vocab size, token size\n",
    "    1. Compare to highest scoring label (Anrede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af4d659a-ef4a-4c21-bc4c-be1f3a54a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {l:[] for l in labels}\n",
    "\n",
    "with open(\"../doctoral_letters/MIEdeep/data/PETsectionclass/full/full_main.tsv\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for d, l in enumerate(lines):\n",
    "        text, lab = l.strip().split(\"\\t\")\n",
    "        texts[lab].append(text)\n",
    "sent_count = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3047f3b5-cfc7-4a5a-bc64-3ec7a4286f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                  Sentence percentage\n",
      "-----------------------------------  ---------------------\n",
      "Abschluss                                             0.18\n",
      "Befunde                                               0.17\n",
      "Zusammenfassung                                       0.17\n",
      "Diagnosen                                             0.14\n",
      "Medikation                                            0.11\n",
      "Anamnese                                              0.08\n",
      "KUBefunde                                             0.07\n",
      "EchoBefunde                                           0.03\n",
      "AllergienUnverträglichkeitenRisiken                   0.02\n",
      "Mix                                                   0.02\n",
      "Anrede                                                0.01\n"
     ]
    }
   ],
   "source": [
    "from numpy import testing\n",
    "\n",
    "l = iter(labels)\n",
    "table = [[n:=next(l), round(len(texts[n])/d,2)] for lab in labels]\n",
    "table = sorted(table, key=lambda x: x[1], reverse = True)\n",
    "testing.assert_almost_equal(sum(i[1] for i in table), 1, decimal=3)\n",
    "table.insert(0, [\"Label\", \"Sentence percentage\"])\n",
    "         \n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342877c0-e7a7-4838-b6bf-215e82892237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/beegfs/scratch/rsari/BertSeqCA/checkpoint-10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24d881c1-c621-4f21-adac-1ba6b0f1e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(num1, num2):\n",
    "    return \"{:.1%}\".format(num1 / num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e51196-b976-4cd0-bb23-612e6ee92a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                  Token count    Vocab size  Ratio\n",
      "-----------------------------------  -------------  ------------  -------\n",
      "Befunde                                     319795          7108  2.2%\n",
      "Zusammenfassung                             258136          6602  2.6%\n",
      "Diagnosen                                   222154          5560  2.5%\n",
      "EchoBefunde                                  91260          2148  2.4%\n",
      "Anamnese                                     87463          4282  4.9%\n",
      "Medikation                                   82140          2189  2.7%\n",
      "Abschluss                                    82102           630  0.8%\n",
      "KUBefunde                                    49686          1381  2.8%\n",
      "Anrede                                       26644           342  1.3%\n",
      "AllergienUnverträglichkeitenRisiken          24239          1435  5.9%\n",
      "Mix                                          21592          2071  9.6%\n"
     ]
    }
   ],
   "source": [
    "tokens = {l:[] for l in labels}\n",
    "\n",
    "for lab in labels:\n",
    "    tokens[lab] = [w for sent in texts[lab] for w in tokenizer.tokenize(sent, padding = True, truncation = True)]\n",
    "\n",
    "vocab = {l:[] for l in labels}\n",
    "\n",
    "for lab in labels:\n",
    "    vocab[lab] = set(tokens[lab])\n",
    "\n",
    "l = iter(labels)\n",
    "table = [[n:=next(l), len(tokens[n]), len(vocab[n]), percent(len(vocab[n]),len(tokens[n]))] for lab in labels]\n",
    "table = sorted(table, key=lambda x:int(x[1]), reverse = True)\n",
    "table.insert(0, [\"Label\", \"Token count\", \"Vocab size\", \"Ratio\"])\n",
    "         \n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4ad6ddc-32d9-4747-9884-92c5c9bd9142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                Data Homogeneity\n",
      "-----------------------------------  ------------------\n",
      "Anrede                               69%\n",
      "AllergienUnverträglichkeitenRisiken  19%\n",
      "KUBefunde                            15%\n",
      "Medikation                           13%\n",
      "Diagnosen                            8%\n",
      "EchoBefunde                          6%\n",
      "Mix                                  5%\n",
      "Abschluss                            5%\n",
      "Zusammenfassung                      4%\n",
      "Befunde                              3%\n",
      "Anamnese                             2%\n"
     ]
    }
   ],
   "source": [
    "# For each label: Choose randomly 10 samples and calculate their homogeneity among each other:\n",
    "import random\n",
    "from statistics import mean\n",
    "unis = {l: [] for l in labels}\n",
    "\n",
    "for label in labels:\n",
    "    for i in range(3):\n",
    "        l = random.choices(texts[label], k=10)\n",
    "        ratio = 0\n",
    "        for d, s in enumerate(l):\n",
    "            if d == 0:\n",
    "                start = set(tokenizer.tokenize(s, padding = True, truncation = True))\n",
    "            else:\n",
    "                sent = set(tokenizer.tokenize(s, padding = True, truncation = True))\n",
    "                uni_rat = (len((sent).intersection(start)))/len(sent.union(start))\n",
    "                unis[label].append(round(uni_rat,2))\n",
    "    unis[label] = mean(unis[label])\n",
    "    \n",
    "l = iter(labels)\n",
    "table = [[n:=next(l), \"{:.0%}\".format(unis[n])] for lab in labels]\n",
    "table = sorted(table, key = lambda x:int(x[1].strip(\"%\")), reverse=True)\n",
    "table.insert(0, [\"Label\", \"Data Homogeneity\"])\n",
    "         \n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0860cd7-c912-4c03-a270-6f3a21a26e35",
   "metadata": {},
   "source": [
    "**Finding:**  \n",
    "Though **Anrede** also has small training data like **Mix**, it scores high because of its low vocab size (since introductory sentences identical) → Low entropy as opposed to Mix being lowest scoring label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ca305d5-1df5-4d0e-8dad-8d5481911b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation of token to vocab size: 0.818 and of vocab size to score: -0.465\n"
     ]
    }
   ],
   "source": [
    "# Correlation of Token/Vocab size with Precision/Recall/F1-Measure\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "data1 = [len(tokens[l]) for l in labels]\n",
    "data2 = [len(vocab[l]) for l in labels]\n",
    "\n",
    "data3 = [float(scores[l][\"f1\"]) for l in labels]\n",
    "\n",
    "corr_sanity, _ = spearmanr(np.array(data1).flatten(), np.array(data2).flatten())\n",
    "corr, _ = spearmanr(np.array(data2).flatten(), np.array(data3).flatten())\n",
    "\n",
    "print('Spearmans correlation of token to vocab size: %.3f and of vocab size to score: %.3f' % (corr_sanity, corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c3a3d02-444b-4c48-b009-3404fa086450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                Token freq\n",
      "-----------------------------------  --------------------------------------------------------------------------------\n",
      "Anrede                               [('-', '10.9%'), ('B', '6.6%'), ('P', '4.5%'), ('I', '4.3%'), ('##D', '3.3%')]\n",
      "Diagnosen                            [('-', '12.0%'), ('/', '2.7%'), ('.', '2.5%'), ('##R', '2.4%'), ('##B', '2.3%')]\n",
      "AllergienUnverträglichkeitenRisiken  [('-', '6.1%'), (',', '4.6%'), (':', '4.0%'), ('##R', '2.8%'), ('##B', '2.7%')]\n",
      "Anamnese                             [('-', '4.8%'), ('.', '4.8%'), ('##e', '2.0%'), (',', '1.6%'), ('##R', '1.3%')]\n",
      "Medikation                           [('-', '14.1%'), ('0', '9.2%'), ('1', '6.5%'), ('mg', '3.2%'), ('##m', '1.7%')]\n",
      "KUBefunde                            [(':', '7.8%'), ('.', '5.5%'), (',', '5.1%'), ('keine', '2.9%'), ('/', '2.0%')]\n",
      "Befunde                              [('-', '5.2%'), ('.', '4.6%'), (',', '2.7%'), ('/', '2.2%'), (':', '1.6%')]\n",
      "EchoBefunde                          [('.', '5.2%'), ('-', '3.3%'), (',', '2.0%'), ('##r', '1.4%'), ('R', '1.2%')]\n",
      "Zusammenfassung                      [('-', '4.4%'), ('.', '4.0%'), ('der', '1.6%'), (',', '1.4%'), ('##R', '1.1%')]\n",
      "Mix                                  [('-', '7.9%'), ('.', '2.3%'), (':', '1.7%'), ('/', '1.7%'), ('##B', '1.5%')]\n",
      "Abschluss                            [('-', '11.3%'), ('I', '4.4%'), ('B', '4.1%'), ('P', '3.9%'), ('##ER', '3.4%')]\n"
     ]
    }
   ],
   "source": [
    "tok_freq = {l:[] for l in labels}\n",
    "\n",
    "for lab in labels:\n",
    "    tok_freq[lab] = sorted([(tok, percent(tokens[lab].count(tok), len(tokens[lab]))) for tok in vocab[lab]], key=lambda x:float(x[1][:-1]), reverse=True)\n",
    "    \n",
    "l = iter(labels)\n",
    "table = [[n:=next(l), tok_freq[n][:5]] for lab in labels]\n",
    "table.insert(0, [\"Label\", \"Token freq\"])\n",
    "\n",
    "print(tabulate(table, headers=\"firstrow\"))\n",
    "\n",
    "with open(\"TokenDistrib.json\", \"w\") as f:\n",
    "    json.dump(tok_freq, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6e4b5-6179-44a4-b370-4449bf8e9944",
   "metadata": {},
   "source": [
    "#### Label EchoBefunde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fdecf8b-b4f7-4882-b08b-352250d1be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"EchoBefunde\"].count(\"Ech\"), tokens[\"Anrede\"].count(\"Ech\") #weird, since in IG: \"Ech\" has positive attribution score for Anrede"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f3ecb-f48b-44fc-8d76-75feec204dcf",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "How then has \"Ech\" positive attribution for Anrede"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc468f-337c-4348-b2d2-1938708c69fe",
   "metadata": {},
   "source": [
    "#### Label Anrede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af04641f-a361-4c2c-97c0-7e22cd017e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"Anrede\"].count(\"wurde\"), tokens[\"EchoBefunde\"].count(\"über\") # explains positive attribution for \"über\" in \"EchoBefunde\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28822278-8943-4fd5-a877-dbaa49854cc2",
   "metadata": {},
   "source": [
    "**See @ferret.ipynb**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57b3c19c-7659-4ec2-b757-e88f133ed3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = tokenizer.tokenize(\"I-PHONE\")\n",
    "label = tag2id[\"Abschluss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b9f2129-ab0d-414f-aa29-44c09b372309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1128, '-'),\n",
       " (0.044, 'I'),\n",
       " (0.0388, 'P'),\n",
       " (0.0343, '##E'),\n",
       " (0.0039, '##HO'),\n",
       " (0.0039, '##N')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set([(round(tokens[id2tag[label]].count(tok)/len(tokens[id2tag[label]]),4), tok) for tok in sent]), key=lambda x:x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eb592e29-8f5b-427c-a45f-7ac24f79d94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.52, 'I', 'Abschluss'),\n",
       " (0.51, '##HO', 'Abschluss'),\n",
       " (0.43, '##E', 'Abschluss'),\n",
       " (0.4, 'P', 'Abschluss'),\n",
       " (0.33, '##N', 'Abschluss'),\n",
       " (0.1, '-', 'Abschluss')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distrib = [(round(l.count(tok)/sum([li.count(tok) for li in tokens.values()]),2), tok, id2tag[i]) for tok in sent for i, l in enumerate(tokens.values()) if i == label]\n",
    "sorted(set(distrib), key=lambda x:x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "464b7781-2853-4703-a795-aeaf6409dae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Abschluss', '##E'),\n",
       " ('Abschluss', '##HO'),\n",
       " ('Abschluss', '##N'),\n",
       " ('Abschluss', 'I'),\n",
       " ('Anrede', 'P'),\n",
       " ('Medikation', '-')}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "set([(id2tag[np.argmax([(l.count(t)/sum([li.count(t) for li in tokens.values()]))/len(tokens[id2tag[i]]) for i,l in enumerate(tokens.values())])], t) for t in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76fe687d-62de-4b35-bf84-45b2e824267e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26644"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[\"Anrede\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "605786c9-8047-4f96-8fbd-c18e75bcc89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 229, 0, 11, 0, 0, 123, 441, 350, 20, 1]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.count(\"Ech\") for l in tokens.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f480cc87-e1fb-4875-8360-c1afc3f08dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                  Vocab size    Amount unique tokens  Ratio\n",
      "-----------------------------------  ------------  ----------------------  -------\n",
      "Befunde                                      7108                    1005  14%\n",
      "Zusammenfassung                              6602                     704  11%\n",
      "Anrede                                        342                      35  10%\n",
      "Anamnese                                     4282                     412  10%\n",
      "Diagnosen                                    5560                     429  8%\n",
      "Medikation                                   2189                     134  6%\n",
      "AllergienUnverträglichkeitenRisiken          1435                      63  4%\n",
      "KUBefunde                                    1381                      31  2%\n",
      "EchoBefunde                                  2148                      44  2%\n",
      "Mix                                          2071                      33  2%\n",
      "Abschluss                                     630                      14  2%\n"
     ]
    }
   ],
   "source": [
    "uniques = {l:[] for l in labels}\n",
    "\n",
    "for l in labels:\n",
    "    other = {k:v for k,v in vocab.items() if k != l}\n",
    "    val_other = [x for y in other.values() for x in y]\n",
    "    uniques[l] = [tok for tok in vocab[l] if tok not in val_other]\n",
    "\n",
    "ratio = lambda x: (len(uniques[x])/(len(vocab[x])))*100\n",
    "\n",
    "l = iter(labels)\n",
    "table = [[n:=next(l), len(vocab[n]),len(uniques[n]),f\"{round(ratio(n))}%\"] for lab in labels]\n",
    "table = sorted(table, key = lambda x:int(x[3][:-1]), reverse=True)\n",
    "table.insert(0, [\"Label\",\"Vocab size\",\"Amount unique tokens\",\"Ratio\"])\n",
    "\n",
    "\n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55c130-98ba-40ee-bad9-ff391eeaa317",
   "metadata": {},
   "source": [
    "**EchoBefunde & Mix (lowest scorings) have biggest amount of shared vocab (ratio to vocab size)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "80e7faf4-908b-4484-9e56-2f7a915ee57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                  Vocab size  Labels with highest amount of shared vocab\n",
      "-----------------------------------  ------------  ----------------------------------------------------------------------------------------------------------------------\n",
      "Anrede                                        342  [('Diagnosen', '85%'), ('Befunde', '79%'), ('Zusammenfassung', '74%'), ('Anamnese', '66%'), ('EchoBefunde', '63%')]\n",
      "Diagnosen                                    5560  [('Befunde', '82%'), ('Zusammenfassung', '77%'), ('Anamnese', '52%'), ('EchoBefunde', '33%'), ('Medikation', '32%')]\n",
      "AllergienUnverträglichkeitenRisiken          1435  [('Befunde', '87%'), ('Zusammenfassung', '85%'), ('Diagnosen', '84%'), ('Anamnese', '72%'), ('Medikation', '54%')]\n",
      "Anamnese                                     4282  [('Zusammenfassung', '80%'), ('Befunde', '79%'), ('Diagnosen', '68%'), ('Mix', '35%'), ('EchoBefunde', '34%')]\n",
      "Medikation                                   2189  [('Befunde', '83%'), ('Zusammenfassung', '83%'), ('Diagnosen', '81%'), ('Anamnese', '63%'), ('Mix', '51%')]\n",
      "KUBefunde                                    1381  [('Befunde', '94%'), ('Zusammenfassung', '86%'), ('Diagnosen', '83%'), ('Anamnese', '75%'), ('EchoBefunde', '56%')]\n",
      "Befunde                                      7112  [('Zusammenfassung', '71%'), ('Diagnosen', '64%'), ('Anamnese', '47%'), ('EchoBefunde', '28%'), ('Medikation', '26%')]\n",
      "EchoBefunde                                  2148  [('Befunde', '93%'), ('Zusammenfassung', '89%'), ('Diagnosen', '86%'), ('Anamnese', '68%'), ('Medikation', '44%')]\n",
      "Zusammenfassung                              6602  [('Befunde', '76%'), ('Diagnosen', '65%'), ('Anamnese', '52%'), ('Mix', '30%'), ('EchoBefunde', '29%')]\n",
      "Mix                                          2071  [('Zusammenfassung', '94%'), ('Befunde', '89%'), ('Diagnosen', '83%'), ('Anamnese', '72%'), ('Medikation', '54%')]\n",
      "Abschluss                                     630  [('Zusammenfassung', '90%'), ('Befunde', '86%'), ('Diagnosen', '78%'), ('Anamnese', '74%'), ('Medikation', '72%')]\n"
     ]
    }
   ],
   "source": [
    "#shared = {\"Anrede\":{\"Befunde\":shared tokens ratio of Anrede vocab}}\n",
    "\n",
    "shared = {k:[] for k in labels}\n",
    "rank = {k:[] for k in labels}\n",
    "\n",
    "for l in labels:\n",
    "    other = {k:v for k,v in vocab.items() if k != l}\n",
    "    shared[l] = [tok for tok in vocab[l] if tok not in uniques[l]] #{\"Anrede\":[tok1, tok2, ..]}\n",
    "    lab = iter(other)\n",
    "    rank[l] = {(q:=next(lab)): percent(len([tok for tok in shared[l] if tok in other[q]]),len(vocab[l])) for label in other}\n",
    "    assert len(shared[l]) + len(uniques[l]) == len(vocab[l])\n",
    "    \n",
    "l = iter(labels)\n",
    "table = [[n:=next(l), len(vocab[n]), sorted(rank[n].items(), key=lambda a: float(a[1][:-1]), reverse=True)[:5]] for lab in labels]\n",
    "table.insert(0, [\"Label\", \"Vocab size\", \"Labels with highest amount of shared vocab\"])\n",
    "\n",
    "print(tabulate(table, headers=\"firstrow\"))\n",
    "\n",
    "def get_ratio(vocab_size, shared_amount):\n",
    "    return round((shared_amount/vocab_size)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "cd852fda-5316-4df2-bd16-a1238986de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top shared vocab of labels: Befunde, Zusammenfassung, Diagnosen → top vocab & token sized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c51b1b-f849-43fc-b27b-430cfe3cde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_sents = {l:{0:[], 25:[], 50:[], 75:[], 100:[]} for l in labels}\n",
    "\n",
    "for l in labels:\n",
    "    file = open(f\"{l}.txt\", \"r\")\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        shared_length = len([s for s in line.split() if s in shared[l]])\n",
    "        ratio = shared_length/len(line.split()) \n",
    "        if ratio == 0:\n",
    "            unq_sents[l][0].append(line)\n",
    "        elif ratio <= 0.25:\n",
    "            unq_sents[l][25].append(line)\n",
    "        elif ratio <= 0.5:\n",
    "            unq_sents[l][50].append(line)\n",
    "        elif ratio <= 0.75:\n",
    "            unq_sents[l][75].append(line)\n",
    "        else:\n",
    "            unq_sents[l][100].append(line)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "fe620d40-3e65-44e0-b6fa-73b3d7ef9c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                Shared token ratio sentence count\n",
      "-----------------------------------  -----------------------------------\n",
      "Anrede                               [1, 1, 197, 203, 0]\n",
      "Diagnosen                            [1207, 2640, 3619, 500, 57]\n",
      "AllergienUnverträglichkeitenRisiken  [361, 244, 280, 140, 6]\n",
      "Anamnese                             [767, 133, 1681, 1608, 429]\n",
      "Medikation                           [1752, 814, 2985, 491, 106]\n",
      "KUBefunde                            [1218, 805, 1638, 493, 40]\n",
      "Befunde                              [2391, 2343, 3237, 1310, 355]\n",
      "EchoBefunde                          [349, 359, 671, 130, 57]\n",
      "Zusammenfassung                      [994, 118, 2419, 5300, 713]\n",
      "Mix                                  [237, 30, 314, 327, 37]\n",
      "Abschluss                            [6493, 550, 948, 1094, 867]\n"
     ]
    }
   ],
   "source": [
    "table = [[l, [len(unq_sents[l][i]) for i in unq_sents[l].keys()]] for l in labels]\n",
    "table.insert(0, [\"Label\", \"Shared token ratio sentence count\"])\n",
    "\n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3fb68d07-146b-404a-b649-4610794ac064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to files:\n",
    "\n",
    "for l in labels:\n",
    "    with open(f\"{l}.txt\", \"w\") as f:\n",
    "        for n in [0,25,50,75,100]:\n",
    "            sents = [f\"{s}\\t{n}\\n\" for s in unq_sents[l][n]]\n",
    "            f.writelines(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed04a6d-c221-42ae-9ae4-208ee919fee7",
   "metadata": {},
   "source": [
    "#### Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d905b2f1-4fce-4e9a-a081-e951fcd2edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                  Average Sentence Length    Token Size    Vocab size  Vocab-Token Ratio\n",
      "-----------------------------------  -------------------------  ------------  ------------  -------------------\n",
      "Anrede                                                    66.3         26644           342  1.3%\n",
      "EchoBefunde                                               58.3         91260          2148  2.4%\n",
      "Befunde                                                   33.2        319918          7112  2.2%\n",
      "Diagnosen                                                 27.7        222154          5560  2.5%\n",
      "Zusammenfassung                                           27          258136          6602  2.6%\n",
      "AllergienUnverträglichkeitenRisiken                       23.5         24239          1435  5.9%\n",
      "Mix                                                       22.8         21592          2071  9.6%\n",
      "Anamnese                                                  18.9         87463          4282  4.9%\n",
      "Medikation                                                13.4         82140          2189  2.7%\n",
      "KUBefunde                                                 11.8         49686          1381  2.8%\n",
      "Abschluss                                                  8.2         82102           630  0.8%\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "avg_len = {l:0 for l in labels}\n",
    "\n",
    "for l in labels:\n",
    "    avg_len[l] = round(mean([len(tokenizer.tokenize(sent)) for sent in texts[l]]),1)\n",
    "    \n",
    "table = [[l, avg_len[l], len(tokens[l]), len(vocab[l]), percent(len(vocab[l]),len(tokens[l]))] for l in labels]\n",
    "table = sorted(table, key=lambda x: int(x[1]), reverse = True)\n",
    "table.insert(0, [\"Label\", \"Average Sentence Length\", \"Token Size\", \"Vocab size\", \"Vocab-Token Ratio\"])\n",
    "\n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIEdeep",
   "language": "python",
   "name": "miedeep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
